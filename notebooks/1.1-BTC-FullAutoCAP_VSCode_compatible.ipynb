{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Automated Cardiac Shape Modeling\n",
    "\n",
    "End-to-End automation of the Cardiac Atlas Project, from SSFP MRI to CIM Mesh. \n",
    "\n",
    "Steps:\n",
    "1. View selection\n",
    "     - Export Slice Info File\n",
    "2. Short axis slice selection\n",
    "3. End-diastole and end-systole selection\n",
    "4. Landmark localization\n",
    "5. Segmentation\n",
    "6. Guide point extraction\n",
    "     - Export guide point file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view selection\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import pydicom\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import nnunet # directly imports local nnunet installation\n",
    "from nnunet.inference.predict import predict_from_folder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5\n",
    "\n",
    "import utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Pydicom: {}'.format(pydicom.__version__))\n",
    "print('TensorFlow: {}'.format(tf.__version__))\n",
    "print('Torch: {}'.format(torch.__version__))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your device has a gpu and the necessary software installed, tensorflow will be able to detect it and display it here. If not, the entire notebook can be run on the CPU, but will take a significantly longer amount of time, particularly if normalization and test time augmentations are utilized during landmark localization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Only use CPU for right now - Set CPU as only available physical device\n",
    "my_devices = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "tf.config.experimental.set_visible_devices(devices= my_devices, device_type='CPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: View Selection\n",
    "\n",
    "### View Classification Option 1: Automated Predictions\n",
    "\n",
    "The automated view selection is designed to automatically identify and select MRI views that are relavent to cardiac modeling. The analysis is designed to be run over a directory containing one or multiple patient subdirectories. The code runs the analysis iteratively over each subdirectory.\n",
    "\n",
    "If you would like to use manual labels, skip ahead to the option 2 for view classification below.\n",
    "\n",
    "The suggested directory structures for each approach are shown below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the analysis over each patient in a directory individually (i.e., analysis for patient 1, then analysis for patient 2.)\n",
    "\n",
    "```bash\n",
    "├── DATA\n",
    "    ├── Patient1\n",
    "    │   ├── 1.dcm\n",
    "    │   ├── 2.dcm \n",
    "    │   ├── 3.dcm          \n",
    "    │   └── ...   \n",
    "    └── Patient2\n",
    "        ├── 1.dcm\n",
    "        ├── 2.dcm \n",
    "        ├── 3.dcm          \n",
    "        └── ...          \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ENTER USER SETTINGS\n",
    "Change the settings below to match the desired patient and correct src, dst, and csv_path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS for the analysis\n",
    "patient = 'EXAMPLE'\n",
    "src = \"../data/raw/Longitudinal Raw MRI/\" + patient          # PATH to the directory containing the desired DICOM files (str)\n",
    "dst = \"../data/processed/\"                       # PATH to the output directory to save dicom files (only valid if save_dicoms = True) (str)\n",
    "\n",
    "# view selection model\n",
    "modelname = 'ResNet50'                            # The neural network to load and used (Options: VGG19, ResNet50, or Xception)\n",
    "use_multiprocessing = False                       # Use multiprocessing to read header info (True or False)\n",
    "\n",
    "# parameters for postprocessing/saving\n",
    "csv_path = '../data/processed/{}/view_predictions.csv'.format(patient)   # PATH to save the generated csv file (only valide if create_csv = True) (str)\n",
    "create_csv = True                                 # Save a .csv file with the series level view predictions (True or False)\n",
    "save_files = True                                 # Save dicom files to new directory (dst) (True or False)\n",
    "save_only_desired = False                         # Save only dicom files corresponding to desired views (True or False)\n",
    "confidence_value = 0.5                            # Only save series if the confidence is > a certain value (set to 0 to save all desired series, regardless of confidence) (float 0-1.0)\n",
    "\n",
    "if not os.path.exists(os.path.join(dst, patient)):\n",
    "    os.mkdir(os.path.join(dst,patient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the view selection scripts\n",
    "from viewselection import ViewSelection\n",
    "\n",
    "# initialize the viewSelector class with appropriate settings\n",
    "viewSelector = ViewSelection(\n",
    "                            src,\n",
    "                            dst,\n",
    "                            modelname,\n",
    "                            csv_path,\n",
    "                            create_csv,\n",
    "                            use_multiprocessing,\n",
    "                            save_files,\n",
    "                            save_only_desired,\n",
    "                            confidence_value\n",
    "                            )\n",
    "\n",
    "# initiate the tensorflow model\n",
    "viewSelector.load_tensorflow_model()\n",
    "\n",
    "# make predictions for src directory\n",
    "viewSelector.complete_view_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the view predictions are saved to the specified csv_path file. We can load in this csv file and \n",
    "# see what views were predicted for each series in the raw MRI dump. \n",
    "selected = pd.read_csv(csv_path)\n",
    "\n",
    "# filter dataframe to desired frames only if desired\n",
    "selected = selected[selected['Confidence'] > confidence_value]\n",
    "selected = selected[selected['Predicted View'].isin(['4CH', '3CH', 'SA', 'LVOT', 'RVOT', '2CH RT', '2CH LT'])]\n",
    "\n",
    "# display dataframe\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display current series and classifications\n",
    "utils.plot_view_classifications(dst, patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate widget to change selections\n",
    "options = selected[['Series Number', 'Series Description', 'Predicted View', 'Confidence']]\n",
    "items = [widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Series {} - {} - {} ({})'.format(row[0], row[1], row[2], row[3]),\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ") for i,row in options.iterrows()]\n",
    "grid = widgets.GridBox(items, layout=widgets.Layout(grid_template_columns=\"repeat(1, 100px)\"))\n",
    "\n",
    "print('Select Desired LAX and SA Series:')\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove undesired series from processed directory\n",
    "selected_series = []\n",
    "for i in range(len(items)):\n",
    "    value = items[i].value\n",
    "    if value == True:\n",
    "        selected_series.append(int(items[i].description.split(' ')[1]))\n",
    "\n",
    "print('Selected Series: ', selected_series)\n",
    "for (root, subdirs, files) in os.walk(dst + patient):\n",
    "    for file in files:\n",
    "        if '.dcm' in file:\n",
    "            dcm = pydicom.dcmread(os.path.join(root, file))\n",
    "            if dcm.SeriesNumber not in selected_series:\n",
    "                os.remove(os.path.join(root, file))\n",
    "                #os.remove(root)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "selected = selected[selected['Series Number'].isin(selected_series)]\n",
    "print('Undesired files removed')\n",
    "\n",
    "# record number of phases from SAX\n",
    "num_phases = np.max([selected['Frames Per Slice']])\n",
    "selected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useability Note\n",
    "\n",
    "If necessary, the predicted views can be corrected using the code below (currently set to Raw NBConvert) in order to limit accidental changes. Enter the series number to change, the currently predicted view, and the actual (or correct) view. The code will copy the dicom files to the correct directory. \n",
    "\n",
    "#### Useability Note\n",
    "The number of frames (or phases) per slice is automatically selected from the SAX stack. In some cases, the number of frames per slice may be different for different views (e.g., 30 frames per slice in the SAX, but only 20 frames per slice in the 4CH view). If this is the case, be sure to appropriately enter/change the number of phases when performing landmark localization predictions below. \n",
    "\n",
    "Similarly, if a dicom file is missing, the number of frames per slice may be inaccurately low. For example, with one dicom missing, the number of frames might be set to 29, when it should actually be 30. Be sure to manually correct this error if it occurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix directory structure if necessary for series that were incorrectly predicted\n",
    "series_num = 8\n",
    "pred_view = 'SA'\n",
    "actual_view = 'RVOT'\n",
    "\n",
    "if not os.path.isdir(os.path.join(dst, patient, actual_view)):\n",
    "    os.mkdir(os.path.join(dst, patient, actual_view))\n",
    "\n",
    "for file in os.listdir(os.path.join(dst, patient, pred_view)):\n",
    "    if '.dcm' in file:\n",
    "        dcm = pydicom.dcmread(os.path.join(dst, patient, pred_view, file))\n",
    "        if dcm.SeriesNumber == series_num:\n",
    "            shutil.move(os.path.join(dst, patient, pred_view, file), os.path.join(dst, patient, actual_view, file))\n",
    "\n",
    "if len(os.listdir(os.path.join(dst, patient, pred_view))) == 0:\n",
    "    os.rmdir(os.path.join(dst, patient, pred_view))\n",
    "    \n",
    "# update dataframe\n",
    "index = selected.index[selected['Series Number'] == series_num].tolist()[0]\n",
    "selected.at[index, 'Predicted View'] = actual_view\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display updated dataframe\n",
    "selected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useability Note\n",
    "\n",
    "If the the views have already been manually identified, the function utils.manual_view_classification() can be used to load the manual selections."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export 1 - Generate Slice Info File\n",
    "\n",
    "Now that the views have been selected, we can export the slice info file for use with the BiV Modelling v2 code. The first code generates a pandas dataframe of this information (used throughout this notebook) while the second code exports it to a txt file (used with BiV Modelling v2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate slice info file for use with python CIM\n",
    "sliceID = 0\n",
    "out = []\n",
    "\n",
    "# check for SA first\n",
    "for subdir in os.listdir(os.path.join(dst, patient)):\n",
    "    #if subdir == 'SA':\n",
    "    if '.' not in subdir:\n",
    "        stored_locs = []\n",
    "        for file in os.listdir(os.path.join(dst, patient, subdir)):\n",
    "            if '.dcm' in file:\n",
    "                dcm = pydicom.dcmread(os.path.join(dst, patient, subdir, file))\n",
    "                #if dcm.SliceLocation in good_locations:\n",
    "                SOPInstanceUID = str(dcm.SOPInstanceUID)\n",
    "                rows = dcm.Rows\n",
    "                cols = dcm.Columns\n",
    "                imagePositionPatient = dcm.ImagePositionPatient\n",
    "                imageOrientationPatient = dcm.ImageOrientationPatient\n",
    "                pixelSpacing = dcm.PixelSpacing\n",
    "\n",
    "                if dcm.SliceLocation not in stored_locs:\n",
    "                    row = [sliceID, file, subdir, dcm.SliceLocation, [rows, cols], imagePositionPatient, imageOrientationPatient, pixelSpacing]\n",
    "                    out.append(row)\n",
    "                    stored_locs.append(dcm.SliceLocation)\n",
    "                    sliceID += 1\n",
    "\n",
    "# generate dataframe\n",
    "slice_info_df = pd.DataFrame(out, columns = ['Slice ID', 'File', 'View', 'Slice Location', 'Size', 'ImagePositionPatient', 'ImageOrientationPatient', 'Pixel Spacing'])\n",
    "\n",
    "# generate mapping dictionary (short-axis slice to slice id) for future use\n",
    "sa_df_sorted = slice_info_df[slice_info_df['View']=='SA'].sort_values('Slice Location', axis=0)\n",
    "sa_mapping_dict = {}\n",
    "for i, row in enumerate(sa_df_sorted.iterrows()):\n",
    "    index, row = row[0], row[1]\n",
    "    slice_id = row['Slice ID']\n",
    "    sa_mapping_dict[slice_id] = i\n",
    "\n",
    "# display slice info\n",
    "slice_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to slice info file\n",
    "with open(os.path.join(dst, patient, 'SliceInfo.txt'), 'w') as f:\n",
    "    for i, row in slice_info_df.iterrows():\n",
    "        sliceID = row['Slice ID']\n",
    "        file = row['File']\n",
    "        view = row['View']\n",
    "        imagePositionPatient = row['ImagePositionPatient']\n",
    "        imageOrientationPatient = row['ImageOrientationPatient']\n",
    "        pixelSpacing = row['Pixel Spacing']\n",
    "        \n",
    "        f.write('{}\\t'.format(file))\n",
    "        f.write('frameID: {}\\t'.format(sliceID))\n",
    "        f.write('timeFrame\\t1\\t')\n",
    "        f.write('ImagePositionPatient\\t')\n",
    "        f.write('{}\\t{}\\t{}\\t'.format(imagePositionPatient[0], imagePositionPatient[1], imagePositionPatient[2]))\n",
    "        f.write('ImageOrientationPatient\\t')\n",
    "        f.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t'.format(imageOrientationPatient[0], imageOrientationPatient[1], imageOrientationPatient[2],\n",
    "                                            imageOrientationPatient[3], imageOrientationPatient[4], imageOrientationPatient[5]))\n",
    "        f.write('Pixel Spacing\\t')\n",
    "        f.write('{}\\t{}\\n'.format(pixelSpacing[0], pixelSpacing[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Phase Selection - ED and ES\n",
    "\n",
    "The following code performs end-systolic phase selection from the short-axis stack of images selected above. The end-diastolic phase is assumed to be 0 (may not necessarily be the case in all scenarios, but has been for all of the cases processed to date). \n",
    "\n",
    "The model performs an ES phase prediction over each short-axis slice, then averages the predictions to produce a final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the phase selection module\n",
    "from phaseselection import PhaseSelection\n",
    "\n",
    "# initialize the phase selector with the list of short-axis images (unordered) and series IDs\n",
    "phaseSelector = PhaseSelection( os.path.join(dst, patient), \n",
    "                                slice_info_df, \n",
    "                                'SA' )\n",
    "\n",
    "# initialize the tensorflow model and inputs\n",
    "phaseSelector.load_tensorflow_model()\n",
    "phaseSelector.generate_mapping_dictionary()\n",
    "phaseSelector.generate_complete_volume()\n",
    "\n",
    "# make phase predictions\n",
    "es_phase = phaseSelector.predict_phase()\n",
    "ed_phase = 0\n",
    "\n",
    "# add prediction to dataframe loaded from csv previously\n",
    "selected.loc[selected['Predicted View'] == 'SA', ['ES Phase Prediction']] = es_phase\n",
    "selected.loc[selected['Predicted View'] == 'SA', ['ED Phase Prediction']] = ed_phase\n",
    "\n",
    "# save this dataframe to a new csv file\n",
    "selected.to_csv('../data/processed/{}/phase_predictions.csv'.format(selected.iloc[0]['Patient ID']))\n",
    "\n",
    "# number of phases in SAX stack\n",
    "es_phase_float = es_phase / num_phases # enables support for patients with differing number of phases per view\n",
    "selected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useability Note\n",
    "\n",
    "If you would like to manually override the ES phase prediction, change the variable, es_phase, in the cell block above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: SA Slice Selection\n",
    "\n",
    "In the next step, we will select the slices of the SA stack that will be useable for cardiac modeling (typically spanning from the apex to the just below the mitral/tricuspid valve planes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the slice selection model\n",
    "MODELPATH = '../models/SliceSelection/slice_selection.hdf5'\n",
    "model = tf.keras.models.load_model(MODELPATH)\n",
    "\n",
    "# find SAX slice IDs\n",
    "sax_ids = slice_info_df[slice_info_df['View'] == 'SA']['Slice ID']\n",
    "min_sax_id = np.min(sax_ids)\n",
    "max_sax_id = np.max(sax_ids)\n",
    "\n",
    "slice_selection_preds = []\n",
    "for i in range(min_sax_id, max_sax_id):\n",
    "    for phase in range(phaseSelector.volume.shape[1]):\n",
    "        image = phaseSelector.volume[i, phase, :, :, 0]\n",
    "    \n",
    "        # resize image\n",
    "        img = np.expand_dims(image, -1)\n",
    "        img = img/np.max(img)\n",
    "\n",
    "        # normalize\n",
    "        img = img*255\n",
    "        img = img.astype(np.uint8)\n",
    "        img = cv2.resize(img, (224,224))\n",
    "\n",
    "        # convert to rgb\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        # make prediction\n",
    "        pred = model.predict(np.expand_dims(img, 0))\n",
    "        location = float(slice_info_df[slice_info_df['Slice ID'] == i]['Slice Location'])\n",
    "        slice_selection_preds.append([phase, i, location, np.argmax(pred)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below organizes the predictions made by the slice selection model, and incorporates manual labels if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of predictions and record slice locations\n",
    "preds_df = pd.DataFrame(slice_selection_preds, columns=['Phase', 'Slice ID', 'Location', 'Prediction'])\n",
    "slice_locations = np.sort([float(x) for x in preds_df['Location'].unique()])\n",
    "\n",
    "# iterate through predicted locations, recording which locations meet acceptance criteria\n",
    "good_locations = []\n",
    "report = []\n",
    "for loc in slice_locations:\n",
    "    \n",
    "    loc_df = preds_df[preds_df['Location'] == loc]\n",
    "    if np.mean(loc_df['Prediction']) > 0.75: # acceptance criteria (>75% of images at this location predicted as acceptable)\n",
    "        label = 'Good'\n",
    "    else:\n",
    "        label = 'Bad'\n",
    "        \n",
    "    slice_id = int(preds_df[preds_df['Location'] == loc].iloc[0]['Slice ID'])\n",
    "    \n",
    "    # check if manual slice info file was loaded\n",
    "    if 'manual_selected_ids' in locals():\n",
    "        if slice_id in manual_selected_ids:\n",
    "            manual_label = 'Good'\n",
    "        else:\n",
    "            manual_label = 'Bad'\n",
    "    else:\n",
    "        manual_label = 'Not available'\n",
    "        \n",
    "    report.append([slice_id, np.round(loc, 1), np.mean(loc_df['Prediction']), label, manual_label])\n",
    "\n",
    "# generate final dataframe and display\n",
    "sa_final_df = pd.DataFrame(report, columns=['Slice ID', 'Slice Location', 'Pred Value', 'Pred Label', 'Manual Label'])\n",
    "sa_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display each slice location, with associated label. \n",
    "# If manually selected cases are available, these labels are automatically used\n",
    "\n",
    "# set backend\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(int(np.ceil(len(slice_locations)/4)), 4, figsize=(10,10))\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        \n",
    "        idx = i*4 + j\n",
    "        if idx > len(slice_locations)-1:\n",
    "            break\n",
    "            \n",
    "        # select row and slice id\n",
    "        row_df = sa_final_df.iloc[idx] \n",
    "        slice_id = row_df['Slice ID']\n",
    "\n",
    "        # the image from the ES phase is automatically selected\n",
    "        ax[i,j].imshow(phaseSelector.volume[slice_id, es_phase, :, :, 0], cmap='gray')\n",
    "        \n",
    "        if \"manual_selected_ids\" in locals():\n",
    "            if slice_id in manual_selected_ids:\n",
    "                ax[i,j].set_title('{} - Accept'.format(int(row_df['Slice Location'])))\n",
    "                ax[i,j].title.set_color('green')\n",
    "            else:\n",
    "                ax[i,j].set_title('{}'.format(int(row_df['Slice Location'])))\n",
    "        else:\n",
    "            if row_df['Pred Label'] == 'Good':\n",
    "                ax[i,j].set_title('{} - Accept'.format(int(row_df['Slice Location'])))\n",
    "                ax[i,j].title.set_color('green')\n",
    "            else:\n",
    "                ax[i,j].set_title('{}'.format(int(row_df['Slice Location'])))\n",
    "        \n",
    "        # format plot\n",
    "        ax[i,j].set_xticks([])\n",
    "        ax[i,j].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useability Note\n",
    "\n",
    "Manually selected SAX slices typically range from base to apex, with every other slice selected. However, both the segmentation and landmark localization models struggle on the most apical and basal slices. Consequently, these slices are optimally excluded from the automated pipeline. In almost all cases I processed, the most basal manual SAX slice was too far basal for use in the automated pipeline. Basal slices that transect the valve planes and/or right ventricular outflow tract should be excluded. \n",
    "\n",
    "I typically select 3 to 4 SAX slices, ranging from just below the valve planes to the apex. I select every other slice, similar to the manual cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make widget with sa slice options\n",
    "items = []\n",
    "for i, row in sa_final_df.iterrows():\n",
    "        if row['Pred Label'] == 'Good':\n",
    "            items.append(widgets.Checkbox(\n",
    "                value=True,\n",
    "                description='Slice {} - {}'.format(i, float(row['Slice Location'])),\n",
    "                disabled=False,\n",
    "                indent=False))\n",
    "        else:\n",
    "            items.append(widgets.Checkbox(\n",
    "                value=False,\n",
    "                description='Slice {} - {}'.format(i, float(row['Slice Location'])),\n",
    "                disabled=False,\n",
    "                indent=False))\n",
    "\n",
    "grid = widgets.GridBox(items, layout=widgets.Layout(grid_template_columns=\"repeat(1, 100px)\"))\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove undesired SA series\n",
    "good_locations = []\n",
    "for i in range(len(items)):\n",
    "    value = items[i].value\n",
    "    if value == True:\n",
    "        good_locations.append(float(items[i].description.split(' ')[-1]))\n",
    "        \n",
    "good_locations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Landmark Localization\n",
    "\n",
    "The following code can be used to perform landmark localization. The points that are predicted are the following:\n",
    "\n",
    "* SA View: right ventricular insertion points\n",
    "* 4CH View: mitral valve insertions, tricuspid valve inserts, left ventricular apex\n",
    "* 3CH View: mitral valve insertions, aortic valve insertions\n",
    "* RVOT View: pulmonary valve insertions\n",
    "\n",
    "#### Useability Note\n",
    "\n",
    "The RV insertion points from the SAX stack are typically fairly accurate; consequently, normalization and test time augmentations (both of which significantly increase required processing time) may not be necessary. For the 4CH, 3CH, and RVOT views, I recommend including both normalization and at least 5 test time augmentations. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Short-Axis RV Inserts\n",
    "\n",
    "Predict the RV insertion points from the SAX stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert selected slice locations into slice IDs\n",
    "selected_sa_ids = list(sa_final_df[sa_final_df['Slice Location'].isin(good_locations)]['Slice ID'])\n",
    "\n",
    "sa_final_df[sa_final_df['Slice Location'].isin(good_locations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from landmarklocalization import LandmarkLocalization\n",
    "\n",
    "# Initiate a landmark localization module in the short-axis view\n",
    "ShortAxisLoc = LandmarkLocalization( os.path.join(dst, patient), slice_info_df, 'SA' )\n",
    "\n",
    "# load model\n",
    "ShortAxisLoc.load_tensorflow_model()\n",
    "\n",
    "# Settings\n",
    "ShortAxisLoc.num_phases = num_phases                             # calculated from view selections\n",
    "ShortAxisLoc.test_time_augmentations = False                     # Use test time augmentations to improve predictions (often not necessary)\n",
    "ShortAxisLoc.normalize_predictions = False                        # Smooth predictions throughout cardiac cycle\n",
    "ShortAxisLoc.number_of_test_augmentations = 5                    # Number of test-time predictions\n",
    "\n",
    "# Generate Input\n",
    "ShortAxisLoc.generate_mapping_dictionary()\n",
    "ShortAxisLoc.generate_complete_volume()\n",
    "\n",
    "# Make landmark predictions for ED phase\n",
    "ShortAxisLoc.predict_landmarks(prediction_phase=0)\n",
    "ed_output = ShortAxisLoc.output\n",
    "\n",
    "# Make landmark predictions for ES phase\n",
    "ShortAxisLoc.predict_landmarks(prediction_phase=int(es_phase_float * ShortAxisLoc.num_phases) )\n",
    "es_output = ShortAxisLoc.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outputs and display inputs/predictions for review\n",
    "volume = ShortAxisLoc.volume\n",
    "\n",
    "cols = 4\n",
    "rows = int(np.ceil(len(selected_sa_ids)/cols))\n",
    "\n",
    "plt.figure(figsize = (16,4*rows))\n",
    "count = 1\n",
    "for i, slice in enumerate(ed_output):\n",
    "    slice_id = slice[0]\n",
    "    if slice_id in selected_sa_ids:\n",
    "        p1 = slice[3]\n",
    "        p2 = slice[4]\n",
    "        image = volume[slice_id, 0, :, :, 0]\n",
    "\n",
    "        ax = plt.subplot(rows, cols, count)\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        if p1 != None:\n",
    "            ax.scatter(x=p1[1], y=p1[0])\n",
    "        if p2 != None:\n",
    "            ax.scatter(x=p2[1], y=p2[0])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(slice_id)\n",
    "        count += 1\n",
    "plt.suptitle('End-Diastolic Short-Axis RV Inserts')   \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (16,4*rows))\n",
    "count = 1\n",
    "for i, slice in enumerate(es_output):\n",
    "    slice_id = slice[0]\n",
    "    if slice_id in selected_sa_ids:\n",
    "        p1 = slice[3]\n",
    "        p2 = slice[4]\n",
    "        image = volume[slice_id, int(es_phase_float * ShortAxisLoc.num_phases), :, :, 0]\n",
    "\n",
    "        ax = plt.subplot(rows, cols, count)\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        if p1 != None:\n",
    "            ax.scatter(x=p1[1], y=p1[0])\n",
    "        if p2 != None:\n",
    "            ax.scatter(x=p2[1], y=p2[0])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(slice_id)\n",
    "        count += 1\n",
    "plt.suptitle('End-Systolic Short-Axis RV Inserts')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the RV insert predictions for both the ED and ES phases\n",
    "sa_df = pd.DataFrame(ed_output, columns=['Slice ID', 'View', 'Time Frame', 'RV1', 'RV2'])\n",
    "sa_df = sa_df.append(pd.DataFrame(es_output, columns=['Slice ID', 'View', 'Time Frame', 'RV1', 'RV2']))\n",
    "sa_df = sa_df[sa_df['Slice ID'].isin(selected_sa_ids)]\n",
    "sa_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "sa_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If necessary, you can use the Annotate module to make corrections to inaccurate landmark predictions. To use this tool, specify the index (first column in the pandas DataFrame above), Slice ID, and landmarks to correct (e.g, ['RV1, 'RV2']). \n",
    "\n",
    "Note - This tool is best used to correct pairs of points. If you are correcting RV1, correct RV2 as well. \n",
    "Note - It does not matter which RV insert you define as RV1 or RV2, as the modeling code later on does not distinguish between the two. This is also true for all valve insertion points (e.g., 'MV1' and 'MV2' are interchangable).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if necessary, update landmark predictions\n",
    "from annotations import Annotate\n",
    "\n",
    "# Settings\n",
    "index = 1\n",
    "slice_id = 16\n",
    "landmarks_to_correct = ['RV1', 'RV2'] # should be list of labels (e.g., ['RV1', 'RV2'])\n",
    "\n",
    "annotator = Annotate(sa_df, volume, index, slice_id, landmarks_to_correct)\n",
    "\n",
    "# set backend\n",
    "%matplotlib qt5\n",
    "\n",
    "annotator.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dataframe and display\n",
    "%matplotlib inline\n",
    "sa_df = annotator.update()\n",
    "sa_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Four Chamber Landmark Localization\n",
    "\n",
    "Predict the MV inserts, TV inserts, and LV apex from the 4CH view. Select only one 4CH slice for inclusion in the final model. \n",
    "\n",
    "\n",
    "#### Useability Note\n",
    "\n",
    "For the landmark localization models, cardiac orientation matters. These models were trained on images with the LV apex pointed towards the top right corner of the image, with the RV (and tricuspid valve) located above the LV (the standard orientation). If this is not the case for your images, utilizing the provided settings \"flip_ud\" (flip image up/down) and \"flip_lr\" (flip image left/right) can be used to achieve the correct orientation. This is necessary to achieve useable predictions if your orientation is incorrect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a landmark localization module in the four chamber view\n",
    "FourChamberLoc = LandmarkLocalization( os.path.join(dst, patient), slice_info_df, '4CH' )\n",
    "\n",
    "# Load tensorflow model and inputs\n",
    "FourChamberLoc.load_tensorflow_model()\n",
    "\n",
    "# Settings\n",
    "FourChamberLoc.num_phases = num_phases                              # Change number of phases if necessary\n",
    "flip_ud = False\n",
    "flip_lr = False\n",
    "FourChamberLoc.test_time_augmentations = True                       # Use test time augmentations to improve predictions (often not necessary)\n",
    "FourChamberLoc.normalize_predictions = True                         # Smooth predictions throughout cardiac cycle\n",
    "FourChamberLoc.number_of_test_augmentations = 5                     # Number of test-time predictions\n",
    "FourChamberLoc.flip_ud = flip_ud\n",
    "FourChamberLoc.flip_lr = flip_lr\n",
    "\n",
    "# Generate Inputs\n",
    "FourChamberLoc.generate_mapping_dictionary()\n",
    "FourChamberLoc.generate_complete_volume()\n",
    "\n",
    "# Make predictions for ED phase\n",
    "FourChamberLoc.predict_landmarks(prediction_phase=0)\n",
    "ed_output = FourChamberLoc.output\n",
    "\n",
    "# Make predictions for ES phase\n",
    "FourChamberLoc.predict_landmarks(prediction_phase=int(es_phase_float * FourChamberLoc.num_phases) )\n",
    "es_output = FourChamberLoc.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display predictions\n",
    "volume = FourChamberLoc.volume\n",
    "\n",
    "cols = 4\n",
    "rows = int(np.ceil(len(ed_output)/cols))\n",
    "\n",
    "plt.figure(figsize = (16,4*rows))\n",
    "for i, slice in enumerate(ed_output):\n",
    "    slice_id = slice[0]\n",
    "    p1 = slice[3]\n",
    "    p2 = slice[4]\n",
    "    p3 = slice[5]\n",
    "    p4 = slice[6]\n",
    "    p5 = slice[7]\n",
    "\n",
    "    image = volume[slice_id, 0, :, :, 0]\n",
    "    if flip_ud == True:\n",
    "        image = np.flipud(image)\n",
    "    elif flip_lr == True:\n",
    "        image = np.fliplr(image)\n",
    "\n",
    "    ax = plt.subplot(rows,cols,i+1)\n",
    "    ax.set_title(slice_id)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    for p in [p1,p2,p3,p4,p5]:\n",
    "        try:\n",
    "            ax.scatter(x=p[1], y=p[0])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "plt.suptitle('End-Diastolic Four Chamber')  \n",
    "plt.show()\n",
    "\n",
    "cols = 4\n",
    "rows = int(np.ceil(len(es_output)/cols))\n",
    "\n",
    "plt.figure(figsize = (16,4*rows))\n",
    "for i, slice in enumerate(es_output):\n",
    "    slice_id = slice[0]\n",
    "    p1 = slice[3]\n",
    "    p2 = slice[4]\n",
    "    p3 = slice[5]\n",
    "    p4 = slice[6]\n",
    "    p5 = slice[7]\n",
    "\n",
    "    image = volume[slice_id, int(es_phase_float * FourChamberLoc.num_phases), :, :, 0]    \n",
    "    \n",
    "    if flip_ud == True:\n",
    "        image = np.flipud(image)\n",
    "    elif flip_lr == True:\n",
    "        image = np.fliplr(image)\n",
    "\n",
    "    ax = plt.subplot(rows,cols,i+1)\n",
    "    ax.set_title(slice_id)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    for p in [p1,p2,p3,p4,p5]:\n",
    "        try:\n",
    "            ax.scatter(x=p[1], y=p[0])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "plt.suptitle('End-Systolic Four Chamber')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT ONE 4CH SLICE FOR USE IN THE MODEL\n",
    "options = list(slice_info_df[slice_info_df['View'] == '4CH']['Slice ID'])\n",
    "items = [widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Slice ID {}'.format(i),\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ") for i in options]\n",
    "grid = widgets.GridBox(items, layout=widgets.Layout(grid_template_columns=\"repeat(1, 100px)\"))\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record selected slice and landmarks\n",
    "selected_4ch_locations = []\n",
    "for i in range(len(items)):\n",
    "    value = items[i].value\n",
    "    if value == True:\n",
    "        selected_4ch_locations.append(int(items[i].description.split(' ')[-1]))\n",
    "        \n",
    "four_chamber_df = pd.DataFrame(ed_output, columns=['Slice ID', 'View', 'Time Frame', 'MV1', 'MV2', 'TV1', 'TV2', 'LVA'])\n",
    "four_chamber_df = four_chamber_df.append(\n",
    "    pd.DataFrame(es_output, columns=['Slice ID', 'View', 'Time Frame', 'MV1', 'MV2', 'TV1', 'TV2', 'LVA'])\n",
    ")\n",
    "four_chamber_df = four_chamber_df[four_chamber_df['Slice ID'].isin(selected_4ch_locations)]\n",
    "four_chamber_df.reset_index(inplace=True, drop=True)\n",
    "four_chamber_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useability Note\n",
    "\n",
    "If the landmark localization predictions are incorrect, they can be manually corrected using the Annotate module. Ideally, this tool will be improved in future versions of this notebook. \n",
    "\n",
    "Referencing the landmark dataframe above, enter the index number (0 or 1), slice ID, and landmarks to correct. The Annotate class will open a matplotlib figure of the view / slice ID selected. Draw a line on the image across the valve plane by clicking twice, once at each valve insertion point. Once the line has been drawn, save the correct valve insertion points by running annotator.update() in the cell block below. The 4CH views are typically accurate; however, the AV and PV insertion points below may need to be corrected. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# if necessary, update landmark predictions\n",
    "from annotations import Annotate\n",
    "\n",
    "# Settings\n",
    "index = 1\n",
    "slice_id = 11\n",
    "landmarks_to_correct = ['TV1', 'TV2'] # should be list of labels (e.g., ['AV1', 'AV2'])\n",
    "\n",
    "annotator = Annotate(four_chamber_df, volume, index, slice_id, landmarks_to_correct)\n",
    "\n",
    "%matplotlib qt5\n",
    "annotator.plot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# update dataframe and display\n",
    "%matplotlib inline\n",
    "four_chamber_df = annotator.update()\n",
    "four_chamber_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Three Chamber Landmark Localization\n",
    "\n",
    "Predict MV insertions and AV insertions from the 3CH view. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initiate a landmark localization module in the three chamber view\n",
    "ThreeChamberLoc = LandmarkLocalization( os.path.join(dst, patient) , slice_info_df, '3CH' )\n",
    "\n",
    "# Load tensorflow model and inputs\n",
    "ThreeChamberLoc.load_tensorflow_model()\n",
    "\n",
    "# Settings\n",
    "ThreeChamberLoc.num_phases = num_phases                # Change number of phases if necessary\n",
    "flip_ud = False\n",
    "flip_lr = False\n",
    "ThreeChamberLoc.normalize_predictions = True\n",
    "ThreeChamberLoc.test_time_augmentations = True\n",
    "ThreeChamberLoc.number_of_test_augmentations = 5\n",
    "ThreeChamberLoc.flip_ud = flip_ud\n",
    "ThreeChamberLoc.flip_lr = flip_lr\n",
    "\n",
    "# Generate Input\n",
    "ThreeChamberLoc.generate_mapping_dictionary()\n",
    "ThreeChamberLoc.generate_complete_volume()\n",
    "\n",
    "# Make predictions for ED phase\n",
    "ThreeChamberLoc.predict_landmarks(prediction_phase=0)\n",
    "ed_output = ThreeChamberLoc.output\n",
    "\n",
    "# Make predictions for ES phase\n",
    "ThreeChamberLoc.predict_landmarks(prediction_phase = int(es_phase_float * ThreeChamberLoc.num_phases))\n",
    "es_output = ThreeChamberLoc.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot 3CH predictions\n",
    "volume = ThreeChamberLoc.volume\n",
    "\n",
    "cols = 4\n",
    "rows = int(np.ceil(len(ed_output)/cols))\n",
    "\n",
    "plt.figure(figsize = (16,4*rows))\n",
    "    \n",
    "for i, slice in enumerate(ed_output):\n",
    "    slice_id = slice[0]\n",
    "    p1 = slice[3]\n",
    "    p2 = slice[4]\n",
    "    p3 = slice[5]\n",
    "    p4 = slice[6]\n",
    "\n",
    "    image = volume[slice_id, 0, :, :, 0]\n",
    "\n",
    "    ax = plt.subplot(rows,cols,i+1)\n",
    "    ax.set_title(slice_id)\n",
    "    \n",
    "    if flip_ud:\n",
    "        image = np.flipud(image)\n",
    "    elif flip_lr:\n",
    "        image = np.fliplr(image)\n",
    "        \n",
    "    ax.imshow(image, cmap='gray')\n",
    "    for p in [p1, p2, p3, p4]:\n",
    "        try:\n",
    "            ax.scatter(x=p[1], y=p[0])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "plt.suptitle('End-Diastolic Three Chamber')      \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (16,4*rows))\n",
    "for i, slice in enumerate(es_output):\n",
    "    slice_id = slice[0]\n",
    "    p1 = slice[3]\n",
    "    p2 = slice[4]\n",
    "    p3 = slice[5]\n",
    "    p4 = slice[6]\n",
    "\n",
    "    image = volume[slice_id, int(es_phase_float * ThreeChamberLoc.num_phases), :, :, 0]\n",
    "\n",
    "    ax = plt.subplot(rows,cols,i+1)\n",
    "    ax.set_title(slice_id)\n",
    "    \n",
    "    if flip_ud:\n",
    "        image = np.flipud(image)\n",
    "    elif flip_lr:\n",
    "        image = np.fliplr(image)\n",
    "        \n",
    "    ax.imshow(image, cmap='gray')\n",
    "    for p in [p1, p2, p3, p4]:\n",
    "        try:\n",
    "            ax.scatter(x=p[1], y=p[0])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "plt.suptitle('End-Systolic Three Chamber')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT ONE 3CH SLICE TO INCLUDE IN THE MODEL\n",
    "options = list(slice_info_df[slice_info_df['View'] == '3CH']['Slice ID'])\n",
    "items = [widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Slice ID {}'.format(i),\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ") for i in options]\n",
    "grid = widgets.GridBox(items, layout=widgets.Layout(grid_template_columns=\"repeat(1, 100px)\"))\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_3ch_locations = []\n",
    "for i in range(len(items)):\n",
    "    value = items[i].value\n",
    "    if value == True:\n",
    "        selected_3ch_locations.append(int(items[i].description.split(' ')[-1]))\n",
    "        \n",
    "three_chamber_df = pd.DataFrame(ed_output, columns=['Slice ID', 'View', 'Time Frame', 'MV1', 'MV2', 'AV1', 'AV2'])\n",
    "three_chamber_df = three_chamber_df.append(\n",
    "    pd.DataFrame(es_output, columns=['Slice ID', 'View', 'Time Frame', 'MV1', 'MV2', 'AV1', 'AV2'])\n",
    ")\n",
    "\n",
    "three_chamber_df = three_chamber_df[three_chamber_df['Slice ID'].isin(selected_3ch_locations)]\n",
    "three_chamber_df.reset_index(inplace=True, drop=True)\n",
    "three_chamber_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if necessary, update landmark predictions\n",
    "from annotations import Annotate\n",
    "\n",
    "# Settings\n",
    "index = 0\n",
    "slice_id = 4\n",
    "labels = ['AV1', 'AV2'] # should be list of labels (e.g., ['AV1', 'AV2'])\n",
    "\n",
    "annotator = Annotate(three_chamber_df, volume, index, slice_id, labels)\n",
    "\n",
    "%matplotlib qt5\n",
    "annotator.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dataframe and display\n",
    "%matplotlib inline\n",
    "three_chamber_df = annotator.update()\n",
    "three_chamber_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 RVOT Landmark Localization\n",
    "\n",
    "Predicte PV insertion points from the RVOT view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a landmark localization module in the RVOT view\n",
    "RVOTLoc = LandmarkLocalization( os.path.join(dst, patient) , slice_info_df, 'RVOT' )\n",
    "\n",
    "# Load tensorflow model\n",
    "RVOTLoc.load_tensorflow_model()\n",
    "\n",
    "# Settings\n",
    "RVOTLoc.num_phases = num_phases                # Change number of phases if necessary\n",
    "RVOTLoc.normalize_predictions = False\n",
    "RVOTLoc.test_time_augmentations = False\n",
    "RVOTLoc.number_of_test_augmentations = 5\n",
    "\n",
    "# Generate input\n",
    "RVOTLoc.generate_mapping_dictionary()\n",
    "RVOTLoc.generate_complete_volume()\n",
    "\n",
    "# Make predictions for ED phase\n",
    "RVOTLoc.predict_landmarks(prediction_phase=0)\n",
    "ed_output = RVOTLoc.output\n",
    "\n",
    "# Make predictions for ES phase\n",
    "RVOTLoc.predict_landmarks(prediction_phase= int(es_phase_float * RVOTLoc.num_phases))\n",
    "es_output = RVOTLoc.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display landmark predictions\n",
    "%matplotlib inline\n",
    "volume = RVOTLoc.volume\n",
    "\n",
    "cols = 4\n",
    "rows = int(np.ceil(len(ed_output)/cols))\n",
    "\n",
    "plt.figure(figsize = (16,4*rows))\n",
    "for i, slice in enumerate(ed_output):\n",
    "    slice_id = slice[0]\n",
    "    p1 = slice[3]\n",
    "    p2 = slice[4]\n",
    "\n",
    "    image = volume[slice_id, 0, :, :, 0]\n",
    "\n",
    "    ax = plt.subplot(rows,cols,i+1)\n",
    "    ax.set_title(slice_id)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    for p in [p1, p2]:\n",
    "        try:\n",
    "            ax.scatter(x=p[1], y=p[0])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (16,4*rows))\n",
    "for i, slice in enumerate(es_output):\n",
    "    slice_id = slice[0]\n",
    "    p1 = slice[3]\n",
    "    p2 = slice[4]\n",
    "\n",
    "    image = volume[slice_id, int(es_phase_float * RVOTLoc.num_phases), :, :, 0]\n",
    "\n",
    "    ax = plt.subplot(rows,cols,i+1)\n",
    "    ax.set_title(slice_id)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    for p in [p1, p2]:\n",
    "        try:\n",
    "            ax.scatter(x=p[1], y=p[0])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT ONE RVOT VIEW TO INCLUDE IN THE MODEL\n",
    "options = list(slice_info_df[slice_info_df['View'] == 'RVOT']['Slice ID'])\n",
    "items = [widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Slice ID {}'.format(i),\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ") for i in options]\n",
    "grid = widgets.GridBox(items, layout=widgets.Layout(grid_template_columns=\"repeat(1, 100px)\"))\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rvot_locations = []\n",
    "for i in range(len(items)):\n",
    "    value = items[i].value\n",
    "    if value == True:\n",
    "        selected_rvot_locations.append(int(items[i].description.split(' ')[-1]))\n",
    "        \n",
    "rvot_df = pd.DataFrame(ed_output, columns=['Slice ID', 'View', 'Time Frame', 'PV1', 'PV2'])\n",
    "rvot_df = rvot_df.append(pd.DataFrame(es_output, columns=['Slice ID', 'View', 'Time Frame', 'PV1', 'PV2']))\n",
    "rvot_df = rvot_df[rvot_df['Slice ID'].isin(selected_rvot_locations)]\n",
    "rvot_df.reset_index(inplace=True, drop=True)\n",
    "rvot_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If necessary, update the PV insertion point predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotations import Annotate\n",
    "\n",
    "# if necessary, update landmark predictions\n",
    "# Settings\n",
    "index = 1\n",
    "slice_id = 12\n",
    "labels = ['PV1', 'PV2'] # should be list of labels (e.g., ['AV1', 'AV2'])\n",
    "\n",
    "annotator = Annotate(rvot_df, volume, index, slice_id, labels)\n",
    "\n",
    "%matplotlib qt5\n",
    "annotator.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update dataframe and display\n",
    "%matplotlib inline\n",
    "rvot_df = annotator.update()\n",
    "rvot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all dataframes to csv\n",
    "landmarks_df = pd.concat([sa_df, four_chamber_df, three_chamber_df, rvot_df])\n",
    "landmarks_df.to_csv(os.path.join( os.path.join(dst, patient), 'landmark_points.csv'))\n",
    "landmarks_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Select 2CH Views\n",
    "\n",
    "We do not include landmark points from the two-chamber views; however, it is still optimal to include the segmentations from these views in the final model. If available, select one two-chamber left and one two-chamber right view for inclusion in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select two-chamber right view, if available\n",
    "two_chamber_df = slice_info_df[slice_info_df['View'] == '2CH RT']\n",
    "\n",
    "cols = 4\n",
    "rows = 1\n",
    "\n",
    "plt.figure(figsize = (16,4*rows))\n",
    "two_chamber_df = two_chamber_df.reset_index()\n",
    "for i, row in two_chamber_df.iterrows():\n",
    "    \n",
    "    slice_id = row['Slice ID']\n",
    "    image = volume[slice_id, 0, :, :, 0]\n",
    "\n",
    "    ax = plt.subplot(rows,cols,i+1)\n",
    "    ax.set_title(slice_id)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = list(slice_info_df[slice_info_df['View'] == '2CH RT']['Slice ID'])\n",
    "items = [widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Slice ID {}'.format(i),\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ") for i in options]\n",
    "grid = widgets.GridBox(items, layout=widgets.Layout(grid_template_columns=\"repeat(1, 100px)\"))\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save selected 2CH RT locations\n",
    "selected_2ch_rt_locations = []\n",
    "for i in range(len(items)):\n",
    "    value = items[i].value\n",
    "    if value == True:\n",
    "        selected_2ch_rt_locations.append(int(items[i].description.split(' ')[-1]))\n",
    "\n",
    "out = []\n",
    "for loc in selected_2ch_rt_locations:\n",
    "    out.append([loc, '2CH RT', 0])  \n",
    "    out.append([loc, '2CH RT', es_phase])\n",
    "    \n",
    "two_chamber_rt_df = pd.DataFrame(out, columns=['Slice ID', 'View', 'Time Frame'])\n",
    "two_chamber_rt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecte two-chamber left views, if available\n",
    "two_chamber_lt_df = slice_info_df[slice_info_df['View'] == '2CH LT']\n",
    "\n",
    "cols = 4\n",
    "rows = 1\n",
    "\n",
    "plt.figure(figsize = (16,4*rows))\n",
    "two_chamber_lt_df = two_chamber_lt_df.reset_index()\n",
    "for i, row in two_chamber_lt_df.iterrows():\n",
    "    \n",
    "    slice_id = row['Slice ID']\n",
    "    image = volume[slice_id, 0, :, :, 0]\n",
    "\n",
    "    ax = plt.subplot(rows,cols,i+1)\n",
    "    ax.set_title(slice_id)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = list(slice_info_df[slice_info_df['View'] == '2CH LT']['Slice ID'])\n",
    "items = [widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Slice ID {}'.format(i),\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ") for i in options]\n",
    "grid = widgets.GridBox(items, layout=widgets.Layout(grid_template_columns=\"repeat(1, 100px)\"))\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save selected 2CH LT locations\n",
    "selected_2ch_lt_locations = []\n",
    "for i in range(len(items)):\n",
    "    value = items[i].value\n",
    "    if value == True:\n",
    "        selected_2ch_lt_locations.append(int(items[i].description.split(' ')[-1]))\n",
    "\n",
    "out = []\n",
    "for loc in selected_2ch_lt_locations:\n",
    "    out.append([loc, '2CHLT', 0])  \n",
    "    out.append([loc, '2CHLT', es_phase])\n",
    "    \n",
    "two_chamber_lt_df = pd.DataFrame(out, columns=['Slice ID', 'View', 'Time Frame'])\n",
    "two_chamber_lt_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Segmentation\n",
    "\n",
    "Myocardial segmentation is performed using nnUnet. Double check that the input and output folders are correct below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define I/O parameters for nnUnet segmentation\n",
    "input_folder = \"../data/final/\" + patient\n",
    "output_folder = \"../data/segmentations/\" + patient\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "# default nnUnet parameters\n",
    "folds = 0\n",
    "save_npz = False\n",
    "num_threads_preprocessing = 1\n",
    "num_threads_nifti_save = 1\n",
    "lowres_segmentations = None\n",
    "part_id = False\n",
    "num_parts = 1\n",
    "mode = \"normal\"\n",
    "\n",
    "# nnunet models / tasks\n",
    "model_folder = \"/home/ubuntu/CAP/CAP-FullAutomation/models/Segmentation\"\n",
    "tasks = ['Task101_SAX', 'Task108_4CH', 'Task107_3CH', 'Task109_RVOT', 'Task110_RVT', 'Task106_2CH']\n",
    "views = ['SA', '4CH', '3CH', 'RVOT', 'RVT', '2CHLT']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For use with the nnUnet pipeline (the model used for segmentation), we need to convert each of the relevant image files to a NIFTI file. The below code used Simple ITK to accomplish this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "# ensure directory for nii files exists\n",
    "if not os.path.isdir(os.path.join(input_folder)):\n",
    "    os.mkdir(os.path.join(input_folder))\n",
    "    \n",
    "# generate input volume\n",
    "ShortAxisLoc = LandmarkLocalization( os.path.join(dst, patient), slice_info_df, 'SA' )\n",
    "ShortAxisLoc.num_phases = num_phases # Change number of phases if necessary\n",
    "ShortAxisLoc.generate_mapping_dictionary()\n",
    "ShortAxisLoc.generate_complete_volume()\n",
    "volume = ShortAxisLoc.volume\n",
    "\n",
    "# select ED and ES images for each cardiac view, and convert to nifti\n",
    "view_dataframes = [sa_df, four_chamber_df, three_chamber_df, rvot_df, two_chamber_rt_df, two_chamber_lt_df]\n",
    "views = ['SA', '4CH', '3CH', 'RVOT', 'RVT', '2CHLT']\n",
    "\n",
    "for view, df in enumerate(view_dataframes):\n",
    "    \n",
    "    # ensure view folder exists\n",
    "    if not os.path.isdir(os.path.join(input_folder, views[view])):\n",
    "        os.mkdir(os.path.join(input_folder, views[view]))\n",
    "        \n",
    "    for i, row in df.iterrows():\n",
    "        slice_id = row['Slice ID']\n",
    "        phase = row['Time Frame']\n",
    "        \n",
    "        # extract image array from volume of all slices\n",
    "        image_array = volume[slice_id, phase, :, :, 0]\n",
    "        \n",
    "        # expand dimensions\n",
    "        image_array = image_array[None, None]\n",
    "        \n",
    "        # spacing defined here - could set to pixel spacing instead of 1,1. First value is simply a dummy value since we only\n",
    "        # have 2D, just needs to be larger than the x and y spacing. \n",
    "        spacing = (999,1,1)\n",
    "        for j, k in enumerate(image_array): # keep for loop here in case additional slices/modalities are needed later\n",
    "            itk_image = sitk.GetImageFromArray(k)\n",
    "            itk_image.SetSpacing(list(spacing)[::-1])\n",
    "\n",
    "            # write nii files to folder for use with nnUnet - only need to save images that need predictions (i.e., ED and ES\n",
    "            # for selected views/slices. \n",
    "            sitk.WriteImage(itk_image, os.path.join(input_folder, views[view],\n",
    "                                                    '{}_{}_{}'.format(views[view], \n",
    "                                                                   slice_id, phase) + \"_%04.0d.nii.gz\" % j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset gpu memory (necessary if tensorflow/landmark models were loaded previously)\n",
    "# ONLY RUN THIS ONCE OR THE KERNEL MAY CRASH\n",
    "tf.keras.backend.clear_session()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code, we will iterate through each of the cardiac views and use the appropriate nnUnet model to make predictions. Models are saved under models/Segmentation/ and are organized by task (i.e., view). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop through each view\n",
    "for i, view in enumerate(views):\n",
    "    \n",
    "    print('*** Making predictions for {} images ***'.format(view))\n",
    "\n",
    "    # Define the trained model to use (Specified by the Task)\n",
    "    model_folder_name = \"../models/Segmentation/{}/nnUNetTrainerV2__nnUNetPlansv2.1/\".format(tasks[i])\n",
    "\n",
    "    view_input_folder = os.path.join(input_folder, view)\n",
    "    view_output_folder = os.path.join(output_folder, view)\n",
    "\n",
    "    # ensure output folder exists\n",
    "    if not os.path.isdir(view_output_folder):\n",
    "        os.mkdir(view_output_folder)\n",
    "        \n",
    "    if len(os.listdir(view_input_folder)) > 0:\n",
    "\n",
    "        # run nnUnet inference directly from folder of 2D nii files\n",
    "        predict_from_folder(model_folder_name, view_input_folder, view_output_folder, folds, save_npz, num_threads_preprocessing,\n",
    "                                num_threads_nifti_save, lowres_segmentations, part_id, num_parts, not False, mode=mode)\n",
    "\n",
    "        print('Done with {}\\n'.format(view))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display generated segmentations\n",
    "import nibabel as nib\n",
    "%matplotlib inline\n",
    "\n",
    "# view some of the segmentations\n",
    "plt.figure(figsize=(16,24))\n",
    "count = 1\n",
    "for i, view in enumerate(views):\n",
    "    \n",
    "    view_output_folder = os.path.join(output_folder, view)\n",
    "    view_input_folder = os.path.join(input_folder, view)\n",
    "    segs = os.listdir(view_output_folder)\n",
    "    segs = [x for x in segs if '.nii.gz' in x]\n",
    "    \n",
    "    if len(segs) > 0:\n",
    "    \n",
    "        # load first image\n",
    "        for idx in range(len(segs)):\n",
    "            subplot = count\n",
    "\n",
    "            # change input name to include modality info (nnUnet formatting)\n",
    "            prefix = segs[idx].split('.')\n",
    "            input_name = prefix[0] + '_0000.' + prefix[1] + '.' + prefix[2]\n",
    "\n",
    "            seg = nib.load(os.path.join(view_output_folder, segs[idx]))\n",
    "            img = nib.load(os.path.join(view_input_folder, input_name))\n",
    "\n",
    "            ax = plt.subplot(6,4,subplot)\n",
    "            ax.imshow(np.array(img.dataobj).T[0,:,:], cmap='gray')\n",
    "            ax.imshow(np.array(seg.dataobj).T[0,:,:], alpha=0.3, cmap='inferno')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.set_title(segs[idx]) \n",
    "            count += 1\n",
    "    \n",
    "plt.show()   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Extract Guide Points from Segmentations and Landmarks\n",
    "\n",
    "Processes the segmentations and landmarks by extracting contours for inclusion in the guide point file. As a part of this process, we perform an inverse transform from image to model coordinates using the affine matrix provided in the DICOM header. Landmark points are loaded from the csv file that was saved previously. To display guide points as they are generated, set display = True in the .extract_guidepoints() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_string(s):\n",
    "    try:\n",
    "        if ',' in s and 'array' not in s:\n",
    "            p1 = int(s.split('[')[1].split(',')[0])\n",
    "            p2 = int(s.split('[')[1].split(',')[1].rstrip(']'))\n",
    "            return np.array(p1, dtype=np.int64), np.array(p2, dtype=np.int64)\n",
    "        elif 'array' in s:\n",
    "            p1 = int(s.split('array([')[1].split(']')[0])\n",
    "            p2 = int(s.split('array([')[2].split('])')[0])\n",
    "            return np.array(p1, dtype=np.int64), np.array(p2, dtype=np.int64)\n",
    "        else:\n",
    "            return s\n",
    "    except:\n",
    "        return s\n",
    "    \n",
    "# reload landmarks dataframe if necessary\n",
    "landmarks_df = pd.read_csv(os.path.join('../data/processed', patient, 'landmark_points.csv'),converters={'object':parse_string})\n",
    "landmarks_df = landmarks_df.drop(columns=['Unnamed: 0']).applymap(parse_string)\n",
    "landmarks_df "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ENTER USER SETTINGS\n",
    "\n",
    "Provide the absolute path to the image (with .nii inputs), segmentation (with .nii segmentations from nnUnet), and final output folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import guidepointprocessing\n",
    "importlib.reload(guidepointprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from guidepointprocessing import GuidePointProcessing\n",
    "\n",
    "# define I/O parameters for nnUnet segmentation\n",
    "image_folder = \"../data/final/\" + patient\n",
    "segment_folder = \"../data/segmentations/\" + patient\n",
    "output_folder = \"../data/processed/\" + patient\n",
    "\n",
    "GuidePoints = GuidePointProcessing(patient,\n",
    "                                  image_folder,\n",
    "                                  segment_folder,\n",
    "                                  output_folder,\n",
    "                                  slice_info_df,\n",
    "                                  landmarks_df)\n",
    "\n",
    "GuidePoints.extract_guidepoints(display = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display guide point results if desired\n",
    "from mpl_toolkits import mplot3d\n",
    "coordinates = []\n",
    "model_folder = '../data/processed/' + patient\n",
    "with open(model_folder + '/GP_ES.txt', 'r') as f:\n",
    "    for i,line in enumerate(f.readlines()):\n",
    "        if i > 0:\n",
    "            points = line.split('\\t')\n",
    "            coordinates.append([float(points[0]), float(points[1]), float(points[2]), points[3]])\n",
    "            \n",
    "len_colors = len(np.unique(np.array(coordinates)[:,3]))\n",
    "from matplotlib import cm\n",
    "new_map = plt.cm.get_cmap('hsv', len_colors)\n",
    "\n",
    "# define colors for each point\n",
    "map = set(np.array(coordinates)[:,3])\n",
    "map_dict = {'AORTA_VALVE': 'r',\n",
    " 'MITRAL_VALVE': 'b',\n",
    " 'RV_INSERT': 'g',\n",
    " 'APEX_POINT': 'y',\n",
    " 'SAX_RV_FREEWALL': '#F2CA19',\n",
    " 'LAX_LV_EPICARDIAL': '#0057E9',\n",
    " 'TRICUSPID_VALVE': 'k',\n",
    " 'LAX_RV_SEPTUM': '#E11845',\n",
    " 'SAX_RV_SEPTUM': '#E11845',\n",
    " 'LAX_RV_EPICARDIAL': '#0057E9',\n",
    " 'LAX_RV_FREEWALL': '#F2CA19',\n",
    " 'PULMONARY_VALVE': 'purple',\n",
    " 'SAX_LV_ENDOCARDIAL': '#87E911',\n",
    " 'SAX_LV_EPICARDIAL': '#0057E9',\n",
    " 'SAX_RV_EPICARDIAL': '#0057E9',\n",
    " 'LAX_LV_ENDOCARDIAL': '#87E911'}\n",
    "\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "labels = []\n",
    "for p1 in coordinates:\n",
    "    lab = p1[3]\n",
    "    if 'LAX' in lab or 'SAX' in lab:\n",
    "        s = 3\n",
    "    else:\n",
    "        s = 10\n",
    "        \n",
    "    if lab in labels:\n",
    "        ax.scatter3D(p1[0], p1[1], p1[2], color=map_dict[lab], s=s)\n",
    "    else:\n",
    "        labels.append(lab)\n",
    "        ax.scatter3D(p1[0], p1[1], p1[2], color=map_dict[lab], label=p1[3], s=s)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move GP and slice info files to the BiV Modelling v2 module\n",
    "import shutil \n",
    "\n",
    "root = '../CIM/BiV_Modelling_v2/test_data/'\n",
    "if not os.path.isdir(root + patient):\n",
    "    os.mkdir(os.path.join(root, patient))\n",
    "    \n",
    "shutil.copyfile(os.path.join(dst, patient, 'GP_ED.txt'), os.path.join(root, patient, 'GP_ED.txt'))\n",
    "shutil.copyfile(os.path.join(dst, patient, 'GP_ES.txt'), os.path.join(root, patient, 'GP_ES.txt'))\n",
    "shutil.copyfile(os.path.join(dst, patient, 'SliceInfo.txt'), os.path.join(root, patient, 'SliceInfo.txt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
